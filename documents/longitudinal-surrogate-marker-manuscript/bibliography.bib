%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Sachs, Michael (NIH/NCI) [E] at 2014-10-27 13:53:44 -0400 


%% Saved with string encoding Unicode (UTF-8) 



@article{rosenbaum1983central,
  title={The central role of the propensity score in observational studies for causal effects},
  author={Rosenbaum, Paul R and Rubin, Donald B},
  journal={Biometrika},
  volume={70},
  number={1},
  pages={41--55},
  year={1983},
  publisher={Oxford University Press}
}
@article{Vieu2016,
archivePrefix = {arXiv},
arxivId = {arXiv:math/0603084v1},
author = {Vieu, Philippe},
eprint = {0603084v1},
file = {:Users/dagniel/Projects/lsa/refs/0603084.pdf:pdf},
keywords = {asymptotic normality,functional data,nonparametric model,quadratic error,regression,wild functional bootstrap},
primaryClass = {arXiv:math},
title = {{Nonparametric regression on functional data : inference and practical aspects}},
year = {2016}
}
@article{Marra2012,
abstract = {We study the coverage properties of Bayesian confidence intervals for the smooth component functions of generalized additive models (GAMs) represented using any penalized regression spline approach. The intervals are the usual generalization of the intervals first proposed by Wahba and Silverman in 1983 and 1985, respectively, to the GAM component context. We present simulation evidence showing these intervals have close to nominal âacross-the-function' frequentist coverage probabilities, except when the truth is close to a straight line/plane function. We extend the argument introduced by Nychka in 1988 for univariate smoothing splines to explain these results. The theoretical argument suggests that close to nominal coverage probabilities can be achieved, provided that heavy oversmoothing is avoided, so that the bias is not too large a proportion of the sampling variability. Otherwise, because the Bayesian intervals account for bias and variance, the coverage probabilities are surprisingly insensitive to the exact choice of smoothing parameter. The theoretical results allow us to derive alternative intervals from a purely frequentist point of view, and to explain the impact that the neglect of smoothing parameter variability has on confidence interval performance. They also suggest switching the target of inference for component-wise intervals away from smooth components in the space of the GAM identifiability constraints. Instead intervals should be produced for each function as if only the other model terms were subject to identifiability constraints. If this is done then coverage probabilities are improved.},
author = {Marra, Giampiero and Wood, Simon N.},
doi = {10.1111/j.1467-9469.2011.00760.x},
file = {:Users/dagniel/Projects/lsa/refs/j.1467-9469.2011.00760.x.pdf:pdf},
isbn = {0303-6898},
issn = {03036898},
journal = {Scandinavian Journal of Statistics},
keywords = {Bayesian confidence interval,Generalized additive model,Penalized regression spline},
number = {1},
pages = {53--74},
title = {{Coverage Properties of Confidence Intervals for Generalized Additive Model Components}},
volume = {39},
year = {2012}
}
@article{Ood2006,
author = {Ood, S Imon N W},
doi = {10.1111/j.1467-842X.2006.00450.x},
file = {:Users/dagniel/Projects/lsa/refs/j.1467-842X.2006.00450.x (1).pdf:pdf},
keywords = {bayesian confidence interval,gam,gcv,generalized additive model,generalized cross,multiple smoothing parameters,penalized regression spline,validation},
number = {4},
pages = {445--464},
title = {{ON CONFIDENCE INTERVALS FOR GENERALIZED ADDITIVE MODELS BASED ON PENALIZED REGRESSION SPLINES University of Bath}},
volume = {48},
year = {2006}
}
@article{Marx1998,
abstract = {Generalized additive models (GAMs) have become an elegant and practical option in model building. Estimation of a smooth GAM component traditionally requires an algorithm that cycles through and updates each smooth, while holding other components at their current estimated fit, until specified convergence. We aim to fit all the smooth components simultaneously. This can be achieved using penalized B-spline or P-spline smoothers for every smooth component, thus transforming GAMs into the generalized linear model framework. Using a large number of equally spaced knots, P-splines purposely overfit each B-spline component. To reduce flexibility, a difference penalty on adjacent B-spline coefficients is incorporated into a penalized version of the Fisher scoring algorithm. Each component has a separate smoothing parameter, and the penalty is optimally regulated through extensions of cross validation or information criterion. An example using logistic additive models provides illustrations of the developments. {\textcopyright} 1998 Elsevier Science B.V. All rights reserved.},
author = {Marx, Brian D. and Eilers, Paul H.C.},
doi = {10.1016/S0167-9473(98)00033-4},
file = {:Users/dagniel/Projects/lsa/refs/896bc3d8ac8c745e5e0ab2fb456281c46e21.pdf:pdf},
isbn = {0167-9473},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {B-splines,Difference penalty,P-splines,Smoothing},
number = {2},
pages = {193--209},
title = {{Direct generalized additive modeling with penalized likelihood}},
volume = {28},
year = {1998}
}
@article{Wood2015,
author = {Wood, Simon N},
file = {:Users/dagniel/Projects/lsa/refs/1467-9868.00374.pdf:pdf},
keywords = {generalized additive model,regression spline,thin plate spline},
number = {1},
pages = {2},
title = {{Thin plate regression splines Duchon spline}},
volume = {65},
year = {2015}
}
@article{Wood2011,
author = {Wood, Simon N},
file = {:Users/dagniel/Projects/lsa/refs/j.1467-9868.2010.00749.x.pdf:pdf},
journal = {Journal of Royal Statistical Society. Series B},
keywords = {adaptive smoothing,generalized additive,generalized additive mixed model,generalized cross-validation,generalized linear model,marginal likelihood,model,model selection,on function regression,penalized,penalized regression splines,restricted maximum likelihood,scalar,stable computation},
number = {1},
pages = {3--36},
title = {{Fast stable REML and ML estimation of semiparametric generalized linear models}},
volume = {73},
year = {2011}
}
@article{Wood2000,
abstract = {Penalized likelihood methods provide a range of practical modelling tools, including spline smoothing, generalized additive models and variants of ridge regression. Selecting the correct weights for penalties is a critical part of using these methods and in the single-penalty case the analyst has several well-founded techniques to choose from. However, many modelling problems suggest a formulation employing multiple penalties, and here general methodology is lacking. A wide family of models with multiple penalties can be {\textregistered}tted to data by iterative solution of the generalized ridge regression problem minimize kW 1=2 (Xp {\`{A}} y)k 2 Â AE m iÂ1 i p H S i p (p is a parameter vector, X a design matrix, S i a non-negative de{\textregistered}nite coef{\textregistered}cient matrix de{\textregistered}ning the i th penalty with associ-ated smoothing parameter i , W a diagonal weight matrix, y a vector of data or pseudodata and aoverall' smoothing parameter included for computational ef{\textregistered}ciency). This paper shows how smoothing parameter selection can be performed efficiently by applying generalized cross-validation to this problem and how this allows non-linear, generalized linear and linear models to be {\textregistered}tted using multiple penalties, substantially increasing the scope of penalized modelling methods. Examples of non-linear modelling, generalized additive modelling and anisotropic smoothing are given.},
author = {Wood, S. N.},
doi = {10.1111/1467-9868.00240},
file = {:Users/dagniel/Projects/lsa/refs/1467-9868.00240 (1).pdf:pdf},
isbn = {1467-9868},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Generalized additive models,Generalized cross-validation,Generalized ridge regression,Model selection,Multiple smoothing parameters,Non-linear modelling,Penalized likelihood,Penalized regression splines},
number = {2},
pages = {413--428},
pmid = {15869905},
title = {{Modelling and smoothing parameter estimation with multiple quadratic penalties}},
volume = {62},
year = {2000}
}
@article{Wood2014,
author = {Wood, Simon N and Journal, Source and Statistical, Royal and Series, Society and Methodology, B Statistical and Wood, N},
file = {:Users/dagniel/Projects/lsa/refs/j.1467-9868.2007.00646.x.pdf:pdf},
keywords = {additive models,akaike,generalized,generalized additive mixed models,generalized approximate cross-validation,generalized cross-validation,penalized likelihood,penalized regression splines,s information criterion,stable computation},
number = {3},
pages = {495--518},
title = {{Fast Stable Direct Fitting and Smoothness Selection for Generalized Additive Models Fast stable direct for generalized fitting and smoothness additive models selection}},
volume = {70},
year = {2014}
}
@article{Wood2004,
abstract = {Representation of generalized additive models (GAM's) using penalized regression splines allows GAM's to be employed in a straightforward manner using penalized regression methods. Not only is inference facilitated by this approach, but it is also possible to integrate model selection in the form of smoothing parameter selection into model fitting in a computationally efficient manner using well founded criteria such as generalized cross-validation. The current fitting and smoothing parameter selection methods for such models are usually effective, but do not provide the level of numerical stability to which users of linear regression packages, for example, are accustomed. In particular the existing methods cannot deal adequately with numerical rank deficiency of the GAM fitting problem, and it is not straightforward to produce methods that can do so, given that the degree of rank deficiency can be smoothing parameter dependent. In addition, models with the potential flexibility of GAM's can also present practical fitting difficulties as a result of indeterminacy in the model likelihood: Data with many zeros fitted by a model with a log link are a good example. In this article it is proposed that GAM's with a ridge penalty provide a practical solution in such circumstances, and a multiple smoothing parameter selection method suitable for use in the presence of such a penalty is developed. The method is based on the pivoted QR decomposition and the singular value decomposition, so that with or without a ridge penalty it has good error propagation properties and is capable of detecting and coping elegantly with numerical rank deficiency. The method also allows mixtures of user specified and estimated smoothing parameters and the setting of lower bounds on smoothing parameters. In terms of computational efficiency, the method compares well with existing methods. A simulation study compares the method to existing methods, including treating GAM's as mixed models},
author = {Wood, Simon N.},
doi = {10.1198/016214504000000980},
file = {:Users/dagniel/Projects/lsa/refs/Stable and Efficient Multiple Smoothing Parameter Estimation for Generalized Additive Models.pdf:pdf},
isbn = {0162-1459},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Generalized additive mixed model,Generalized cross-validation,Penalized quasi-likelihood,REML,Regularization,Ridge regression,Smoothing spline analysis of variance,Spline,Stable computation},
number = {467},
pages = {673--686},
pmid = {1774},
title = {{Stable and efficient multiple smoothing parameter estimation for generalized additive models}},
volume = {99},
year = {2004}
}
@article{Goldsmith2011,
abstract = {We develop fast fitting methods for generalized functional linear models. The functional predictor is projected onto a large number of smooth eigenvectors and the coefficient function is estimated using penalized spline regression; confidence intervals based on the mixed model framework are obtained. Our method can be applied to many functional data designs including functions measured with and without error, sparsely or densely sampled. The methods also extend to the case of multiple functional predictors or functional predictors with a natural multilevel structure. The approach can be implemented using standard mixed effects software and is computationally fast. The methodology is motivated by a study of white-matter demyelination via diffusion tensor imaging (DTI). The aim of this study is to analyze differences between various cerebral white- matter tract property measurements of multiple sclerosis (MS) patients and controls. While the statistical developments proposed here were motivated by the DTI study, the methodology is designed and presented in generality and is applicable to many other areas of scientific research. An online appendix provides R implementations of all simulations.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Goldsmith, Jeff and Bobb, Jennifer and Crainiceanu, Ciprian M. and Caffo, Brian and Reich, Daniel},
doi = {10.1198/jcgs.2010.10007},
eprint = {NIHMS150003},
file = {:Users/dagniel/Projects/lsa/refs/Penalized Functional Regression.pdf:pdf},
isbn = {1191001202},
issn = {10618600},
journal = {Journal of Computational and Graphical Statistics},
keywords = {Functional regression,Mixed models,Principal components,Smoothing splines},
number = {4},
pages = {830--851},
pmid = {1000000221},
title = {{Penalized functional regression}},
volume = {20},
year = {2011}
}
@article{Wood2006,
abstract = {Generalized additive models represented using low rank penalized regression splines, esti- mated by penalized likelihood maximisation and with smoothness selected by generalized cross validation or similar criteria, provide a computationally efficient general framework for practical smooth modelling. Various authors have proposed approximate Bayesian in- terval estimates for such models, based on extensions of the work of Wahba, G. (1983) [Bayesian confidence intervals for the cross validated smoothing spline. 45, 133â150] and Silverman, B.W. (1985) [Some aspects of the spline smoothing approach to nonparametric regression curve fitting. 47, 1â52] on smoothing spline models of Gaussian data, but testing of such intervals has been rather limited and there is little supporting theory for the approximations used in the generalized case. This paper aims to im- prove this situation by providing simulation tests and obtaining asymptotic results supporting the approximations employed for the generalized case. The simulation results suggest that while across-the-model performance is good, component-wise coverage probabilities are not as reliable. Since this is likely to result from the neglect of smoothing parameter variability, a simple and efficient simulation method is proposed to account for smoothing parameter un- certainty: this is demonstrated to substantially improve the performance of component-wise intervals.},
author = {Wood, Simon N.},
doi = {10.1111/j.1467-842X.2006.00450.x},
file = {:Users/dagniel/Projects/lsa/refs/j.1467-842X.2006.00450.x.pdf:pdf},
isbn = {1369-1473},
issn = {13691473},
journal = {Australian and New Zealand Journal of Statistics},
keywords = {Bayesian confidence interval,Generalized additive model (GAM),Generalized cross validation (GCV),Multiple smoothing parameters,Penalized regression spline},
number = {4},
pages = {445--464},
title = {{On confidence intervals for generalized additive models based on penalized regression splines}},
volume = {48},
year = {2006}
}
@article{Wood2000a,
abstract = {Penalized likelihood methods provide a range of practical modelling tools, including spline smoothing, generalized additive models and variants of ridge regression. Selecting the correct weights for penalties is a critical part of using these methods and in the single-penalty case the analyst has several well-founded techniques to choose from. However, many modelling problems suggest a formulation employing multiple penalties, and here general methodology is lacking. A wide family of models with multiple penalties can be {\textregistered}tted to data by iterative solution of the generalized ridge regression problem minimize kW 1=2 (Xp {\`{A}} y)k 2 Â AE m iÂ1 i p H S i p (p is a parameter vector, X a design matrix, S i a non-negative de{\textregistered}nite coef{\textregistered}cient matrix de{\textregistered}ning the i th penalty with associ-ated smoothing parameter i , W a diagonal weight matrix, y a vector of data or pseudodata and aoverall' smoothing parameter included for computational ef{\textregistered}ciency). This paper shows how smoothing parameter selection can be performed efficiently by applying generalized cross-validation to this problem and how this allows non-linear, generalized linear and linear models to be {\textregistered}tted using multiple penalties, substantially increasing the scope of penalized modelling methods. Examples of non-linear modelling, generalized additive modelling and anisotropic smoothing are given.},
author = {Wood, S. N.},
doi = {10.1111/1467-9868.00240},
file = {:Users/dagniel/Projects/lsa/refs/1467-9868.00240.pdf:pdf},
isbn = {1467-9868},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Generalized additive models,Generalized cross-validation,Generalized ridge regression,Model selection,Multiple smoothing parameters,Non-linear modelling,Penalized likelihood,Penalized regression splines},
number = {2},
pages = {413--428},
pmid = {15869905},
title = {{Modelling and smoothing parameter estimation with multiple quadratic penalties}},
volume = {62},
year = {2000}
}
@article{Oviedo2011,
abstract = {This paper is devoted to the R package fda.usc which includes some utilities for func- tional data analysis. This package carries out exploratory and descriptive analysis of functional data analyzing its most important features such as depth measurements or functional outliers detection, among others. The R package fda.usc also includes func- tions to compute functional regression models, with a scalar response and a functional explanatory data via non-parametric functional regression, basis representation or func- tional principal components analysis. There are natural extensions such as functional linear models and semi-functional partial linear models, which allow non-functional co- variates and factors and make predictions. The functions of this package complement and incorporate the two main references of functional data analysis: The R package fda and the functions implemented by Ferraty and Vieu (2006).},
author = {Oviedo, Manuel},
doi = {10.18637/jss.v051.i04},
file = {:Users/dagniel/Projects/lsa/refs/v51i04 (2).pdf:pdf},
issn = {1548-7660},
keywords = {FDA package},
number = {4},
pages = {92},
title = {{Utilities for Statistical Computing in Functional Data Analysis : The Package fda . usc}},
volume = {51},
year = {2011}
}
@article{Reiss2017a,
abstract = {{\textcopyright} 2017 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America. A number of classical approaches to nonparametric regression have recently been extended to the case of functional predictors. This article introduces a new method of this type, which extends intermediate-rank penalized smoothing to scalar-on-function regression. In the proposed method, which we call principal coordinate ridge regression, one regresses the response on leading principal coordinates defined by a relevant distance among the functional predictors, while applying a ridge penalty. Our publicly available implementation, based on generalized additive modeling software, allows for fast optimal tuning parameter selection and for extensions to multiple functional predictors, exponential family-valued responses, and mixed-effects models. In an application to signature verification data, principal coordinate ridge regression, with dynamic time warping distance used to define the principal coordinates, is shown to outperform a functional generalized linear model. Supplementary materials for this article are available online.},
author = {Reiss, Philip T. and Miller, David L. and Wu, Pei Shien and Hua, Wen Yu},
doi = {10.1080/10618600.2016.1217227},
file = {:Users/dagniel/Projects/lsa/refs/Penalized Nonparametric Scalar on Function Regression via Principal Coordinates (1).pdf:pdf},
issn = {15372715},
journal = {Journal of Computational and Graphical Statistics},
keywords = {Dynamic time warping,Functional regression,Generalized additive model,Kernel ridge regression,Multidimensional scaling},
number = {3},
pages = {569--578},
publisher = {Taylor {\&} Francis},
title = {{Penalized Nonparametric Scalar-on-Function Regression via Principal Coordinates}},
url = {https://doi.org/10.1080/10618600.2016.1217227},
volume = {26},
year = {2017}
}
@article{Bouchentouf2014,
author = {Bouchentouf, Amina Angelika and Hamel, El Hadj and Rabhi, Abbes and Soltani, Sarah},
doi = {10.7726/jams.2014.1003},
file = {:Users/dagniel/Projects/lsa/refs/JAMS.2014.1003.pdf:pdf},
keywords = {2000 mathematics subject classi,62g05,62g07,62g20,62n02,censored data,conditional hazard function,functional index process,functional variable,ication,nonparametric estimation,primary,secondary,single,small ball probability},
number = {1},
pages = {20--41},
title = {{Nonparametric Estimation of Hazard Function with Functional Explicatory Variable in Single Functional Index}},
volume = {1},
year = {2014}
}
@article{Hadjila2018,
author = {Hadjila, Tabti and Ahmed, Ait Saidi},
doi = {10.1080/03610926.2016.1213294},
file = {:Users/dagniel/Projects/lsa/refs/Estimation and simulation of conditional hazard function in the quasi associated framework when the observations are linked via a functional single.pdf:pdf},
issn = {0361-0926},
journal = {Communications in Statistics---Theory and Methods},
keywords = {Conditional hazard function,functional random vari},
number = {4},
pages = {816--838},
publisher = {Taylor {\&} Francis},
title = {{Communications in Statistics - Theory and Methods Estimation and simulation of conditional hazard function in the quasi-associated framework when the observations are linked via a functional single- index structure}},
url = {https://doi.org/10.1080/03610926.2016.1213294},
volume = {47},
year = {2018}
}
@article{Ghosal,
archivePrefix = {arXiv},
arxivId = {arXiv:1812.04680v1},
author = {Ghosal, Rahul and Maity, Arnab and Carolina, North},
eprint = {arXiv:1812.04680v1},
file = {:Users/dagniel/Projects/lsa/refs/1812.04680.pdf:pdf},
title = {{Hypothesis Testing in Functional Linear Concurrent Regression}}
}
@article{Li2007,
author = {Li, Jiexiang and Tran, Lanh Tat},
doi = {10.1016/j.jmva.2007.03.002},
file = {:Users/dagniel/Projects/lsa/refs/82374478.pdf:pdf},
keywords = {asymptotic normality,hazard rate,kernel density estimator,random field,spatial process},
pages = {1337--1355},
title = {{Hazard rate estimation on random fields}},
volume = {98},
year = {2007}
}
@article{Berrendero2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1812.00721v1},
author = {Berrendero, R and Bueno-larraz, Beatriz and Cuevas, Antonio},
eprint = {arXiv:1812.00721v1},
file = {:Users/dagniel/Projects/lsa/refs/1812.00721.pdf:pdf},
keywords = {functional data,kernel meth-,logistic regression,reproducing kernel hilbert spaces},
number = {1989},
pages = {1--31},
title = {{On functional logistic regression via RKHS's}},
year = {2013}
}
@article{Laksaci2011,
author = {Laksaci, Ali and Vieu, Philippe},
doi = {10.1214/11-EJS600},
file = {:Users/dagniel/Projects/lsa/refs/euclid.ejs.1301318250.pdf:pdf},
keywords = {and phrases,entropy,estimators,functional data,kernel,received october 2010,semi-metric space,uniform almost complete convergence},
pages = {159--171},
title = {{Kernel regression with functional response}},
volume = {5},
year = {2011}
}
@article{Reiss2017b,
author = {Reiss, Philip T and Goldsmith, Jeff and Shang, Han Lin and Ogden, R Todd},
doi = {10.1111/insr.12163},
file = {:Users/dagniel/Projects/lsa/refs/insr.12163 (1).pdf:pdf},
keywords = {functional additive model,functional generalised linear model,functional linear model,functional polynomial regression,functional single-index model,non-parametric functional regression},
pages = {228--249},
title = {{Methods for Scalar-on-Function Regression}},
year = {2017}
}
@article{Ferraty2010,
author = {Ferraty, F and Vieu, P},
doi = {10.1080/10485250903089930},
file = {:Users/dagniel/Projects/lsa/refs/Locally modelled regression and functional data.pdf:pdf},
isbn = {1048525090},
title = {{Locally modelled regression and functional data}},
volume = {5252},
year = {2010}
}
@article{Laksaci2014,
author = {Laksaci, Ali and Mechab, Boubaker},
doi = {10.1080/15598608.2014.847766},
file = {:Users/dagniel/Projects/lsa/refs/Conditional Hazard Estimate for Functional Random Fields.pdf:pdf},
issn = {1559-8608},
journal = {Journal of Statistical Theory and Practice},
number = {2},
pages = {192--220},
publisher = {Taylor {\&} Francis},
title = {{Conditional Hazard Estimate for Functional Random Fields Conditional Hazard Estimate for Functional}},
url = {http://dx.doi.org/10.1080/15598608.2014.847766 https://doi.org/10.1080/15598608.2014.847766},
volume = {8},
year = {2014}
}
@article{Ferraty,
author = {Ferraty, Fr{\'{e}}d{\'{e}}ric and Laksaci, Ali and Tadj, Amel and Vieu, Philippe},
doi = {10.1016/j.jspi.2009.07.019},
file = {:Users/dagniel/Projects/lsa/refs/Rate{\_}of{\_}uniform{\_}consistency{\_}for{\_}nonparam.pdf:pdf},
keywords = {uniform almost complete convergence},
title = {{Author ' s personal copy Rate of uniform consistency for nonparametric estimates with functional variables}}
}
@article{Wood2016,
author = {Wood, Simon N and Pya, Natalya and Benjamin, S},
file = {:Users/dagniel/Downloads/uasa{\_}a{\_}1180986{\_}sm0752.pdf:pdf},
pages = {1--24},
title = {{Supplementary material : Smoothing parameter and model selection for general smooth models B Penalized regression spline consistency under LAML}},
year = {2016}
}
@article{mclean2014,
author = {McLean, Mathew W. and Hooker, Giles and Staicu, Ana-Maria and Scheipl, Fabian and Ruppert, David},
doi = {10.1080/10618600.2012.729985},
file = {:Users/dagniel/Projects/lsa/refs/Functional Generalized Additive Models.pdf:pdf},
issn = {1061-8600},
journal = {Journal of Computational and Graphical Statistics},
month = {jan},
number = {1},
pages = {249--269},
title = {{Functional Generalized Additive Models}},
url = {http://www.tandfonline.com/doi/abs/10.1080/10618600.2012.729985},
volume = {23},
year = {2014}
}
@article{Wood2016a,
abstract = {This paper discusses a general framework for smoothing parameter estimation for models with regular likelihoods constructed in terms of unknown smooth functions of covariates. Gaussian random effects and parametric terms may also be present. By construction the method is numerically stable and convergent, and enables smoothing parameter uncertainty to be quantified. The latter enables us to fix a well known problem with AIC for such models. The smooth functions are represented by reduced rank spline like smoothers, with associated quadratic penalties measuring function smoothness. Model estimation is by penalized likelihood maximization, where the smoothing parameters controlling the extent of penalization are estimated by Laplace approximate marginal likelihood. The methods cover, for example, generalized additive models for non-exponential family responses (for example beta, ordered categorical, scaled t distribution, negative binomial and Tweedie distributions), generalized additive models for location scale and shape (for example two stage zero inflation models, and Gaussian location-scale models), Cox proportional hazards models and multivariate additive models. The framework reduces the implementation of new model classes to the coding of some standard derivatives of the log likelihood.},
archivePrefix = {arXiv},
arxivId = {1511.03864},
author = {Wood, Simon N. and Pya, Natalya and S{\"{a}}fken, Benjamin},
doi = {10.1080/01621459.2016.1180986},
eprint = {1511.03864},
file = {:Users/dagniel/Projects/lsa/refs/Smoothing Parameter and Model Selection for General Smooth Models.pdf:pdf},
isbn = {0162-1459},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {AIC,Additive model,Distributional regression,GAM,Location scale and shape model,Ordered categorical regression,Penalized regression spline,REML,Smooth Cox model,Smoothing parameter uncertainty,Statistical algorithm,Tweedie distribution},
number = {516},
pages = {1548--1563},
title = {{Smoothing Parameter and Model Selection for General Smooth Models}},
volume = {111},
year = {2016}
}
@article{Reiss2017,
abstract = {{\textcopyright} 2017 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America. A number of classical approaches to nonparametric regression have recently been extended to the case of functional predictors. This article introduces a new method of this type, which extends intermediate-rank penalized smoothing to scalar-on-function regression. In the proposed method, which we call principal coordinate ridge regression, one regresses the response on leading principal coordinates defined by a relevant distance among the functional predictors, while applying a ridge penalty. Our publicly available implementation, based on generalized additive modeling software, allows for fast optimal tuning parameter selection and for extensions to multiple functional predictors, exponential family-valued responses, and mixed-effects models. In an application to signature verification data, principal coordinate ridge regression, with dynamic time warping distance used to define the principal coordinates, is shown to outperform a functional generalized linear model. Supplementary materials for this article are available online.},
author = {Reiss, Philip T. and Miller, David L. and Wu, Pei Shien and Hua, Wen Yu},
doi = {10.1080/10618600.2016.1217227},
file = {:Users/dagniel/Library/Application Support/Mendeley Desktop/Downloaded/Reiss et al. - 2017 - Penalized Nonparametric Scalar-on-Function Regression via Principal Coordinates.pdf:pdf;:Users/dagniel/Projects/lsa/refs/Penalized Nonparametric Scalar on Function Regression via Principal Coordinates.pdf:pdf},
issn = {15372715},
journal = {Journal of Computational and Graphical Statistics},
keywords = {Dynamic time warping,Functional regression,Generalized additive model,Kernel ridge regression,Multidimensional scaling},
number = {3},
pages = {569--578},
publisher = {Taylor {\&} Francis},
title = {{Penalized Nonparametric Scalar-on-Function Regression via Principal Coordinates}},
url = {https://doi.org/10.1080/10618600.2016.1217227},
volume = {26},
year = {2017}
}
@article{Parast2017,
abstract = {Given the long follow-up periods that are often required for treatment or intervention studies, the potential to use surrogate markers to decrease the required follow-up time is a very attractive goal. However, previous studies have shown that using inadequate markers or making inappropriate assumptions about the relationship between the primary outcome and surrogate marker can lead to inaccurate conclusions regarding the treatment effect. Currently available methods for identifying and validating surrogate markers tend to rely on restrictive model assumptions and/or focus on uncensored outcomes. The ability to use such methods in practice when the primary outcome of interest is a time-to-event outcome is difficult because of censoring and missing surrogate information among those who experience the primary outcome before surrogate marker measurement. In this paper, we propose a novel definition of the proportion of treatment effect explained by surrogate information collected up to a specified time in the setting of a time-to-event primary outcome. Our proposed approach accommodates a setting where individuals may experience the primary outcome before the surrogate marker is measured. We propose a robust non-parametric procedure to estimate the defined quantity using censored data and use a perturbation-resampling procedure for variance estimation. Simulation studies demonstrate that the proposed procedures perform well in finite samples. We illustrate the proposed procedures by investigating two potential surrogate markers for diabetes using data from the Diabetes Prevention Program. Copyright {\textcopyright} 2017 John Wiley {\&} Sons, Ltd.},
author = {Parast, Layla and Cai, Tianxi and Tian, Lu},
doi = {10.1002/sim.7220},
file = {:Users/dagniel/Projects/lsa/refs/sim.7220.pdf:pdf},
isbn = {0277-6715},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {non-parametric methods,robust procedures,smoothing,survival analysis},
number = {11},
pages = {1767--1782},
pmid = {28088843},
title = {{Evaluating surrogate marker information using censored data}},
volume = {36},
year = {2017}
}
@article{Parast2016,
abstract = {Competing compartment models of different complexities have been used for the quantitative analysis of dynamic contrast-enhanced magnetic resonance imaging data. We present a spatial elastic net approach that allows to estimate the number of compartments for each voxel such that the model complexity is not fixed a priori. A multi-compartment approach is considered, which is translated into a restricted least square model selection problem. This is done by using a set of basis functions for a given set of candidate rate constants. The form of the basis functions is derived from a kinetic model and thus describes the contribution of a specific compartment. Using a spatial elastic net estimator, we chose a sparse set of basis functions per voxel, and hence, rate constants of compartments. The spatial penalty takes into account the voxel structure of an image and performs better than a penalty treating voxels independently. The proposed estimation method is evaluated for simulated images and applied to an in vivo dataset.},
archivePrefix = {arXiv},
arxivId = {arXiv:1512.06881v1},
author = {Parast, Layla and Mcdermott, Mary M. and Tian, Lu},
doi = {10.1002/sim.6820},
eprint = {arXiv:1512.06881v1},
isbn = {6136232529},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {Kernel estimation,Nonparametric,Robust,Surrogate marker,Treatment effect},
number = {10},
pages = {1637--1653},
pmid = {24123120},
title = {{Robust estimation of the proportion of treatment effect explained by surrogate marker information}},
volume = {35},
year = {2016}
}
@article{Muller2008,
abstract = {In commonly used functional regression models, the regression of a scalar or functional response on the functional predictor is assumed to be linear. This means that the response is a linear function of the functional principal component scores of the predictor process. We relax the linearity assumption and propose to replace it by an additive structure, leading to a more widely applicable and much more flexible framework for functional regression models. The proposed functional additive regression models are suitable for both scalar and functional responses. The regularization needed for effective estimation of the regression parameter function is implemented through a projection on the eigenbasis of the covariance operator of the functional components in the model. The use of functional principal components in an additive rather than linear way leads to substantial broadening of the scope of functional regression models and emerges as a natural approach, because the uncorrelatedness of the functional pr...},
author = {M{\"{u}}ller, Hans-Georg and Yao, Fang},
doi = {10.1198/016214508000000751},
file = {:Users/dagniel/Projects/lsa/refs/016214508000000751.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {additive model,asymptotics,functional data analysis,functional regression,linear model,principal components,smoothing,stochastic processes},
number = {484},
pages = {1534--1544},
title = {{Functional Additive Models}},
url = {http://www.tandfonline.com/doi/abs/10.1198/016214508000000751},
volume = {103},
year = {2008}
}
@article{Parast2016a,
abstract = {Competing compartment models of different complexities have been used for the quantitative analysis of dynamic contrast-enhanced magnetic resonance imaging data. We present a spatial elastic net approach that allows to estimate the number of compartments for each voxel such that the model complexity is not fixed a priori. A multi-compartment approach is considered, which is translated into a restricted least square model selection problem. This is done by using a set of basis functions for a given set of candidate rate constants. The form of the basis functions is derived from a kinetic model and thus describes the contribution of a specific compartment. Using a spatial elastic net estimator, we chose a sparse set of basis functions per voxel, and hence, rate constants of compartments. The spatial penalty takes into account the voxel structure of an image and performs better than a penalty treating voxels independently. The proposed estimation method is evaluated for simulated images and applied to an in vivo dataset.},
archivePrefix = {arXiv},
arxivId = {arXiv:1512.06881v1},
author = {Parast, Layla and Mcdermott, Mary M. and Tian, Lu},
doi = {10.1002/sim.6820},
eprint = {arXiv:1512.06881v1},
isbn = {6136232529},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {Kernel estimation,Nonparametric,Robust,Surrogate marker,Treatment effect},
number = {10},
pages = {1637--1653},
pmid = {24123120},
title = {{Robust estimation of the proportion of treatment effect explained by surrogate marker information}},
volume = {35},
year = {2016}
}
@article{crambes2009smoothing,
  title={Smoothing splines estimators for functional linear regression},
  author={Crambes, Christophe and Kneip, Alois and Sarda, Pascal and others},
  journal={The Annals of Statistics},
  volume={37},
  number={1},
  pages={35--72},
  year={2009},
  publisher={Institute of Mathematical Statistics}
}

@article{Yao2005,
author = {Yao, Fang and M{\"{u}}ller, Hans-Georg and Wang, Jane-Ling},
doi = {10.1198/016214504000001745},
file = {:Users/dagniel/Library/Application Support/Mendeley Desktop/Downloaded/Yao, M{\"{u}}ller, Wang - 2005 - Functional Data Analysis for Sparse Longitudinal Data.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {asymptotics,conditioning,confidence band,measurement error,principal components,simultaneous inference},
month = {jun},
number = {470},
pages = {577--590},
title = {{Functional Data Analysis for Sparse Longitudinal Data}},
url = {http://www.tandfonline.com/doi/abs/10.1198/016214504000001745},
volume = {100},
year = {2005}
}

@article{renard2003validation,
  title={Validation of a longitudinally measured surrogate marker for a time-to-event endpoint},
  author={Renard, Didier and Geys, Helena and Molenberghs, Geert and Burzykowski, Tomasz and Buyse, Marc and Vangeneugden, Tony and Bijnens, Luc},
  journal={Journal of Applied Statistics},
  volume={30},
  number={2},
  pages={235--247},
  year={2003},
  publisher={Taylor \& Francis}
}


@article{pryseley2010using,
  title={Using earlier measures in a longitudinal sequence as a potential surrogate for a later one},
  author={Pryseley, Assam and Tilahun, Abel and Alonso, Ariel and Molenberghs, Geert},
  journal={Computational statistics \& data analysis},
  volume={54},
  number={5},
  pages={1342--1354},
  year={2010},
  publisher={Elsevier}
}

@article{cleary2018contribution,
  title={Contribution of NIH funding to new drug approvals 2010--2016},
  author={Cleary, Ekaterina Galkina and Beierlein, Jennifer M and Khanuja, Navleen Surjit and McNamee, Laura M and Ledley, Fred D},
  journal={Proceedings of the National Academy of Sciences},
  volume={115},
  number={10},
  pages={2329--2334},
  year={2018},
  publisher={National Acad Sciences}
}

@misc{stat,
	Author = {STAT},
	Howpublished = {{ https://www.statnews.com/2018/06/06/drug-development-speed-new-medicines/}},Title = {30 years is too long to wait for new medicines. There are ways to speed up drug development},
	Year = {2018}}

@article{Hammer96,
  title={A trial comparing nucleoside monotherapy with combination therapy in HIV-infected adults with CD4 cell counts from 200 to 500 per cubic millimeter},
  author={Hammer, S.M. and Katzenstein, D.A. and Hughes, M.D. and Gundacker, H. and Schooley, R.T. and Haubrich, R.H. and Henry, W.K. and Lederman, M.M. and Phair, J.P. and Niu, M. and others},
  journal={New England Journal of Medicine},
  volume={335},
  number={15},
  pages={1081--1090},
  year={1996},
  publisher={Mass Medical Soc}
}

@article{parast2016robust,
  title={Robust estimation of the proportion of treatment effect explained by surrogate marker information},
  author={Parast, Layla and McDermott, Mary M and Tian, Lu},
  journal={Statistics in medicine},
  volume={35},
  number={10},
  pages={1637--1653},
  year={2016},
  publisher={Wiley Online Library}
}

@article{freedman1992statistical,
	Author = {Freedman, Laurence S and Graubard, Barry I and Schatzkin, Arthur},
	Journal = {Statistics in medicine},
	Number = {2},
	Pages = {167--178},
	Publisher = {Wiley Online Library},
	Title = {Statistical validation of intermediate endpoints for chronic diseases},
	Volume = {11},
	Year = {1992}}
	
@article{prentice1989surrogate,
	Author = {Prentice, Ross L},
	Journal = {Statistics in medicine},
	Number = {4},
	Pages = {431--440},
	Publisher = {Wiley Online Library},
	Title = {Surrogate endpoints in clinical trials: definition and operational criteria},
	Volume = {8},
	Year = {1989}}
	
@book{burzykowski2005evaluation,
	Author = {Burzykowski, Tomasz and Molenberghs, Geert and Buyse, Marc},
	Publisher = {Springer},
	Title = {The evaluation of surrogate endpoints},
	Year = {2005}}
	
@article{wang2002measure,
	Author = {Wang, Yue and Taylor, Jeremy MG},
	Journal = {Biometrics},
	Number = {4},
	Pages = {803--812},
	Publisher = {Wiley Online Library},
	Title = {A measure of the proportion of treatment effect explained by a surrogate marker},
	Volume = {58},
	Year = {2002}}


@article{gilbert2008evaluating,
	Author = {Gilbert, Peter B and Hudgens, Michael G},
	Journal = {Biometrics},
	Number = {4},
	Pages = {1146--1154},
	Publisher = {Wiley Online Library},
	Title = {Evaluating candidate principal surrogate endpoints},
	Volume = {64},
	Year = {2008}}
	
@article{royce2017surrogate,
  title={Surrogate end points for all-cause mortality in men with localized unfavorable-risk prostate cancer treated with radiation therapy vs radiation therapy plus androgen deprivation therapy: a secondary analysis of a randomized clinical trial},
  author={Royce, Trevor J and Chen, Ming-Hui and Wu, Jing and Loffredo, Marian and Renshaw, Andrew A and Kantoff, Philip W and D?amico, Anthony V},
  journal={JAMA oncology},
  volume={3},
  number={5},
  pages={652--658},
  year={2017},
  publisher={American Medical Association}
}


@article{agyemang2018herpes,
  title={Herpes simplex virus shedding rate: Surrogate outcome for genital herpes recurrence frequency and lesion rates, and phase 2 clinical trials end point for evaluating efficacy of antivirals},
  author={Agyemang, Elfriede and Magaret, Amalia S and Selke, Stacy and Johnston, Christine and Corey, Larry and Wald, Anna},
  journal={The Journal of infectious diseases},
  volume={218},
  number={11},
  pages={1691--1699},
  year={2018},
  publisher={Oxford University Press US}
}


@article{inker2016early,
  title={Early change in urine protein as a surrogate end point in studies of IgA nephropathy: an individual-patient meta-analysis},
  author={Inker, Lesley A and Mondal, Hasi and Greene, Tom and Masaschi, Taylor and Locatelli, Francesco and Schena, Francesco P and Katafuchi, Ritsuko and Appel, Gerald B and Maes, Bart D and Li, Philip K and others},
  journal={American Journal of Kidney Diseases},
  volume={68},
  number={3},
  pages={392--401},
  year={2016},
  publisher={Elsevier}
}

@article{chen2003proportion,
  title={Proportion of treatment effect (PTE) explained by a surrogate marker},
  author={Chen, Cong and Wang, Hongwei and Snapinn, Steven M},
  journal={Statistics in medicine},
  volume={22},
  number={22},
  pages={3449--3459},
  year={2003},
  publisher={Wiley Online Library}
}

@article{deslandes2007assessing,
  title={Assessing surrogacy from the joint modelling of multivariate longitudinal data and survival: application to clinical trial data on chronic lymphocytic leukaemia},
  author={Deslandes, Emmanuelle and Chevret, Sylvie},
  journal={Statistics in medicine},
  volume={26},
  number={30},
  pages={5411--5421},
  year={2007},
  publisher={Wiley Online Library}
}

@article{taylor2002surrogate,
  title={Surrogate markers and joint models for longitudinal and survival data},
  author={Taylor, Jeremy MG and Wang, Yan},
  journal={Controlled Clinical Trials},
  volume={23},
  number={6},
  pages={626--634},
  year={2002},
  publisher={Elsevier}
}

@article{tsiatis1995modeling,
  title={Modeling the relationship of survival to longitudinal data measured with error. Applications to survival and CD4 counts in patients with AIDS},
  author={Tsiatis, AA and Degruttola, Victor and Wulfsohn, MS},
  journal={Journal of the American Statistical Association},
  volume={90},
  number={429},
  pages={27--37},
  year={1995},
  publisher={Taylor \& Francis}
}

@article{henderson2002identification,
  title={Identification and efficacy of longitudinal markers for survival},
  author={Henderson, Robin and Diggle, Peter and Dobson, Angela},
  journal={Biostatistics},
  volume={3},
  number={1},
  pages={33--50},
  year={2002},
  publisher={Oxford University Press}
}
